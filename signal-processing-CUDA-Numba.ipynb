{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
   "colab": {
     "name": "Signal_Processing_CUDA_Numba.ipynb",
     "provenance": [],
     "accelerator": "GPU"
   },
   "kernelspec": {
     "display_name": "Python 3",
     "name": "python3"
   }
 },
 "cells": [
   {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
       "# Signal Processing with CUDA and Numba\n",
       "\n",
       "This notebook demonstrates GPU acceleration for signal processing using Numba:\n",
       "- FFT-like operations on time series data\n",
       "- Memory coalescing optimization\n",
       "- Performance comparison between CPU and GPU implementations\n",
       "- Visualization of results"
     ]
   },
   {
     "cell_type": "code",
     "metadata": {
       "id": "setup"
     },
     "source": [
       "# Install required packages\n",
       "!pip install numba seaborn\n",
       "\n",
       "# Import libraries\n",
       "import numpy as np\n",
       "from numba import cuda, vectorize\n",
       "import matplotlib.pyplot as plt\n",
       "import seaborn as sns\n",
       "from time import time\n",
       "import pandas as pd\n",
       "import math"
     ]
   },
   {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
       "## Signal Generation\n",
       "Generate synthetic test signal with multiple frequency components"
     ]
   },
   {
     "cell_type": "code",
     "metadata": {
       "id": "signal_gen"
     },
     "source": [
       "def generate_signal(n_samples, frequencies=[10, 25, 50]):\n",
       "    \"\"\"Generate test signal with multiple frequencies and noise\"\"\"\n",
       "    t = np.linspace(0, 1, n_samples)\n",
       "    signal = np.zeros_like(t)\n",
       "    for f in frequencies:\n",
       "        signal += np.sin(2 * np.pi * f * t)\n",
       "    return t, signal + np.random.normal(0, 0.1, n_samples)\n",
       "\n",
       "# Test signal generation\n",
       "t_test, signal_test = generate_signal(1000)\n",
       "plt.plot(t_test[:100], signal_test[:100])\n",
       "plt.title('Example Signal (first 100 samples)')\n",
       "plt.show()"
     ]
   },
   {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
       "## GPU Implementations\n",
       "1. Vectorized window function - Simple element-wise operation\n",
       "2. Custom FFT kernel - Demonstrates memory coalescing"
     ]
   },
   {
     "cell_type": "code",
     "metadata": {
       "id": "gpu_impl"
     },
     "source": [
       "@vectorize(['complex64(float32)'], target='cuda')\n",
       "def apply_window(x):\n",
       "    \"\"\"Hanning window function - vectorized for GPU\"\"\"\n",
       "    return 0.5 * (1 - np.cos(2 * np.pi * x))\n",
       "\n",
       "@cuda.jit\n",
       "def compute_fft_elements(signal, output):\n",
       "    \"\"\"Custom FFT-like operation with memory coalescing\"\"\"\n",
       "    idx = cuda.grid(1)\n",
       "    if idx < signal.size:\n",
       "        # Sequential memory access pattern\n",
       "        sum_real = 0.0\n",
       "        sum_imag = 0.0\n",
       "        for k in range(signal.size):\n",
       "            angle = -2.0 * np.pi * idx * k / signal.size\n",
       "            sum_real += signal[k] * math.cos(angle)\n",
       "            sum_imag += signal[k] * math.sin(angle)\n",
       "        output[idx] = (sum_real * sum_real + sum_imag * sum_imag) ** 0.5"
     ]
   },
   {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
       "## Analysis Function\n",
       "Wrapper function to handle CPU/GPU implementation selection and memory management"
     ]
   },
   {
     "cell_type": "code",
     "metadata": {
       "id": "analysis"
     },
     "source": [
       "def analyze_signal(signal, use_gpu=True):\n",
       "    \"\"\"Analyze signal using either CPU or GPU implementation\"\"\"\n",
       "    if not use_gpu:\n",
       "        return np.fft.fft(signal)\n",
       "    \n",
       "    # GPU memory management\n",
       "    signal_gpu = cuda.to_device(signal.astype(np.float32))\n",
       "    output_gpu = cuda.to_device(np.zeros_like(signal, dtype=np.float32))\n",
       "    \n",
       "    # Configure kernel execution\n",
       "    threadsperblock = 256\n",
       "    blockspergrid = (signal.size + threadsperblock - 1) // threadsperblock\n",
       "    \n",
       "    # Launch kernel\n",
       "    compute_fft_elements[blockspergrid, threadsperblock](signal_gpu, output_gpu)\n",
       "    \n",
       "    return output_gpu.copy_to_host()"
     ]
   },
   {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
       "## Benchmarking and Visualization"
     ]
   },
   {
     "cell_type": "code",
     "metadata": {
       "id": "benchmark"
     },
     "source": [
       "def run_benchmark():\n",
       "    \"\"\"Run performance comparison across different signal sizes\"\"\"\n",
       "    sizes = [1024, 4096, 16384, 65536]\n",
       "    results = []\n",
       "    \n",
       "    for size in sizes:\n",
       "        t, signal = generate_signal(size)\n",
       "        \n",
       "        # CPU timing\n",
       "        t0 = time()\n",
       "        cpu_result = analyze_signal(signal, use_gpu=False)\n",
       "        cpu_time = time() - t0\n",
       "        \n",
       "        # GPU timing\n",
       "        t0 = time()\n",
       "        gpu_result = analyze_signal(signal, use_gpu=True)\n",
       "        gpu_time = time() - t0\n",
       "        \n",
       "        results.append({\n",
       "            'size': size,\n",
       "            'cpu_time': cpu_time,\n",
       "            'gpu_time': gpu_time,\n",
       "            'speedup': cpu_time/gpu_time,\n",
       "            'signal_size': size\n",
       "        })\n",
       "        \n",
       "        print(f\"Size {size}: CPU {cpu_time:.4f}s, GPU {gpu_time:.4f}s, Speedup {cpu_time/gpu_time:.2f}x\")\n",
       "    \n",
       "    return results, t, signal, cpu_result, gpu_result\n",
       "\n",
       "def plot_results(results, t, signal, cpu_result, gpu_result):\n",
       "    \"\"\"Create visualizations of signal analysis and performance\"\"\"\n",
       "    sns.set_style(\"whitegrid\")\n",
       "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
       "    \n",
       "    # Original signal plot\n",
       "    axes[0,0].plot(t[:100], signal[:100], 'b-', label='Signal')\n",
       "    axes[0,0].set_title('Original Signal (first 100 samples)')\n",
       "    axes[0,0].set_xlabel('Time')\n",
       "    axes[0,0].set_ylabel('Amplitude')\n",
       "    \n",
       "    # Frequency domain comparison\n",
       "    freqs = np.fft.fftfreq(len(signal))\n",
       "    axes[0,1].plot(freqs[:len(freqs)//2], np.abs(cpu_result)[:len(cpu_result)//2], \n",
       "                   'b-', alpha=0.7, label='CPU FFT')\n",
       "    axes[0,1].plot(freqs[:len(freqs)//2], np.abs(gpu_result)[:len(gpu_result)//2], \n",
       "                   'r--', alpha=0.7, label='GPU FFT')\n",
       "    axes[0,1].set_title('Frequency Domain Comparison')\n",
       "    axes[0,1].set_xlabel('Frequency')\n",
       "    axes[0,1].set_ylabel('Magnitude')\n",
       "    axes[0,1].legend()\n",
       "    \n",
       "    # Performance scaling\n",
       "    sizes = [r['signal_size'] for r in results]\n",
       "    speedups = [r['speedup'] for r in results]\n",
       "    axes[1,0].plot(sizes, speedups, 'go-')\n",
       "    axes[1,0].set_xscale('log')\n",
       "    axes[1,0].set_xlabel('Signal Size')\n",
       "    axes[1,0].set_ylabel('Speedup (CPU/GPU)')\n",
       "    axes[1,0].set_title('GPU Speedup vs Signal Size')\n",
       "    \n",
       "    # Time comparison\n",
       "    times = pd.DataFrame({\n",
       "        'Size': [str(r['signal_size']) for r in results],\n",
       "        'CPU': [r['cpu_time'] for r in results],\n",
       "        'GPU': [r['gpu_time'] for r in results]\n",
       "    }).melt(id_vars=['Size'], var_name='Platform', value_name='Time')\n",
       "    \n",
       "    sns.barplot(data=times, x='Size', y='Time', hue='Platform', ax=axes[1,1])\n",
       "    axes[1,1].set_title('Execution Time Comparison')\n",
       "    axes[1,1].set_ylabel('Time (seconds)')\n",
       "    \n",
       "    plt.tight_layout()\n",
       "    plt.show()"
     ]
   },
   {
     "cell_type": "code",
     "metadata": {
       "id": "run_analysis"
     },
     "source": [
       "# Run analysis and create visualizations\n",
       "results, t, signal, cpu_result, gpu_result = run_benchmark()\n",
       "plot_results(results, t, signal, cpu_result, gpu_result)"
     ]
   }
 ]
}


{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Word_Length_Analysis_CUDA_Numba.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ortimus/nvidia-numba-basics/blob/main/gpu-acceleration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAXW4xP5dR-0"
      },
      "source": [
        "# Word Length Analysis with CUDA and Numba\n",
        "\n",
        "This notebook demonstrates GPU acceleration using Numba for a simple text analysis task.\n",
        "\n",
        "Key concepts covered:\n",
        "- Basic CUDA kernel implementation\n",
        "- Memory transfer between CPU and GPU\n",
        "- Atomic operations\n",
        "- Grid/block configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup_cell",
        "outputId": "1a6a118b-5b9b-40c2-b875-86bbc6ff5a3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install numba"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba) (0.43.0)\n",
            "Requirement already satisfied: numpy<2.1,>=1.22 in /usr/local/lib/python3.11/dist-packages (from numba) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imports"
      },
      "source": [
        "import numpy as np\n",
        "from numba import cuda, vectorize\n",
        "import math\n",
        "from time import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrfIY4jKdR-1"
      },
      "source": [
        "## CPU Implementation\n",
        "Basic sequential implementation for comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpu_impl"
      },
      "source": [
        "def count_word_lengths_cpu(words):\n",
        "    max_length = 20\n",
        "    counts = np.zeros(max_length, dtype=np.int32)\n",
        "    for word in words:\n",
        "        if len(word) < max_length:\n",
        "            counts[len(word)] += 1\n",
        "    return counts"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byfo1u5XdR-2"
      },
      "source": [
        "## GPU Implementations\n",
        "Two approaches: vectorized and CUDA kernel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpu_impl"
      },
      "source": [
        "@vectorize(['int32(int32)'], target='cuda')\n",
        "def get_word_length(length):\n",
        "    return min(length, 20)\n",
        "\n",
        "@cuda.jit\n",
        "def count_word_lengths_gpu(word_lengths, counts):\n",
        "    idx = cuda.grid(1)\n",
        "    if idx < word_lengths.size:\n",
        "        length = word_lengths[idx]\n",
        "        if length < 20:\n",
        "            cuda.atomic.add(counts, length, 1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "parZBrZrdR-2"
      },
      "source": [
        "## Main Analysis Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "analysis_func"
      },
      "source": [
        "def analyze_text(text, use_gpu=True):\n",
        "    words = text.split()\n",
        "    word_lengths = np.array([len(word) for word in words], dtype=np.int32)\n",
        "\n",
        "    if not use_gpu:\n",
        "        return count_word_lengths_cpu(words)\n",
        "\n",
        "    d_lengths = cuda.to_device(word_lengths)\n",
        "    d_counts = cuda.to_device(np.zeros(20, dtype=np.int32))\n",
        "\n",
        "    threadsperblock = 256\n",
        "    blockspergrid = (word_lengths.size + threadsperblock - 1) // threadsperblock\n",
        "\n",
        "    count_word_lengths_gpu[blockspergrid, threadsperblock](d_lengths, d_counts)\n",
        "\n",
        "    return d_counts.copy_to_host()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG3ve0SKdR-3"
      },
      "source": [
        "## Test and Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "benchmark",
        "outputId": "8d494ac1-fb89-4e36-e2c4-793018081ada",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create test data\n",
        "words = [\"python\", \"cuda\", \"gpu\", \"computing\"] * 250000\n",
        "text = \" \".join(words)\n",
        "\n",
        "# CPU benchmark\n",
        "t0 = time()\n",
        "cpu_counts = analyze_text(text, use_gpu=False)\n",
        "cpu_time = time() - t0\n",
        "\n",
        "# GPU benchmark\n",
        "t0 = time()\n",
        "gpu_counts = analyze_text(text, use_gpu=True)\n",
        "gpu_time = time() - t0\n",
        "\n",
        "print(f\"CPU time: {cpu_time:.4f}s\")\n",
        "print(f\"GPU time: {gpu_time:.4f}s\")\n",
        "print(f\"Speedup: {cpu_time/gpu_time:.2f}x\")\n",
        "\n",
        "# Compare results\n",
        "print(\"\\nWord length frequencies:\")\n",
        "for length, count in enumerate(gpu_counts):\n",
        "    if count > 0:\n",
        "        print(f\"Length {length}: {count}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU time: 1.7584s\n",
            "GPU time: 0.5260s\n",
            "Speedup: 3.34x\n",
            "\n",
            "Word length frequencies:\n",
            "Length 3: 250000\n",
            "Length 4: 250000\n",
            "Length 6: 250000\n",
            "Length 9: 250000\n"
          ]
        }
      ]
    }
  ]
}